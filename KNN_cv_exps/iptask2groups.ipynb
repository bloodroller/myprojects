{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nearest_neighbors\n",
    "import cross_validation\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import sklearn.datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Task9,10,11\n",
    "buf=fetch_20newsgroups(subset='train',remove=('headers', 'footers', 'quotes'))\n",
    "ans=buf['target']\n",
    "buf=buf['data']\n",
    "#buf=[''.join((c if c.isalnum() else ' ') for c in s.lower()) for s in buf]\n",
    "#buf2=[c.split() for c in buf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Task12\n",
    "indptr = [0]\n",
    "indices = []\n",
    "data = []\n",
    "vocabulary = {}\n",
    "for d in buf2:\n",
    "    for term in d:\n",
    "        index = vocabulary.setdefault(term, len(vocabulary))\n",
    "        indices.append(index)\n",
    "        data.append(1)\n",
    "    indptr.append(len(indices))\n",
    "shape1=len(vocabulary)\n",
    "shape0=len(buf2)\n",
    "data1=csr_matrix((data, indices, indptr),shape=(shape0,shape1), dtype=float).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Task14\n",
    "for k in [\"euclidean\",\"cosine\"]:\n",
    "    start=time.clock()\n",
    "    a=cross_validation.knn_cross_val_score(data1,ans,[1,2,3,4,5,6,7,8,9,10],score=\"accuracy\",cv=cross_validation.kfold(data1.shape[0],3),weights=False,metric=k,strategy=\"brute\",test_block_size=20)\n",
    "    print(\"time =\",time.clock()-start)\n",
    "    for i in a:\n",
    "        mean=np.sum(a[i])/len(a[i])\n",
    "        print(\"k =\",i,k,\"mean =\",mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Task13\n",
    "transformer=TfidfTransformer()\n",
    "tfidf = transformer.fit_transform(data1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы убедились на предыдущей выборке, что точность на фолдах кросс-валидации алгоритмов \"brute\" и \"my_own\" совпадает, но имеет значительно разную скорость, поэтому на данной выборке лучше воспользоваться наиболее быстрым алгоритмом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time = 14.004056000000002\n",
      "k = 1 euclidean mean = 0.153349162681\n",
      "k = 2 euclidean mean = 0.1146362273\n",
      "k = 3 euclidean mean = 0.107300191158\n",
      "k = 4 euclidean mean = 0.103234306875\n",
      "k = 5 euclidean mean = 0.098726546914\n",
      "k = 6 euclidean mean = 0.0956328547409\n",
      "k = 7 euclidean mean = 0.0937769815767\n",
      "k = 8 euclidean mean = 0.0920094788613\n",
      "k = 9 euclidean mean = 0.0890927384941\n",
      "k = 10 euclidean mean = 0.085645962907\n",
      "time = 11.759024000000004\n",
      "k = 1 cosine mean = 0.582464158061\n",
      "k = 2 cosine mean = 0.549230682632\n",
      "k = 3 cosine mean = 0.552590236047\n",
      "k = 4 cosine mean = 0.556832814359\n",
      "k = 5 cosine mean = 0.559307022889\n",
      "k = 6 cosine mean = 0.554622334557\n",
      "k = 7 cosine mean = 0.551352159262\n",
      "k = 8 cosine mean = 0.54993806804\n",
      "k = 9 cosine mean = 0.547639709907\n",
      "k = 10 cosine mean = 0.544723321053\n"
     ]
    }
   ],
   "source": [
    "#Task14\n",
    "for k in [\"euclidean\",\"cosine\"]:\n",
    "    start=time.clock()\n",
    "    a=cross_validation.knn_cross_val_score(tfidf,ans,[1,2,3,4,5,6,7,8,9,10],score=\"accuracy\",cv=cross_validation.kfold(tfidf.shape[0],3),weights=False,metric=k,strategy=\"brute\",test_block_size=20)\n",
    "    print(\"time =\",time.clock()-start)\n",
    "    for i in a:\n",
    "        mean=np.sum(a[i])/len(a[i])\n",
    "        print(\"k =\",i,k,\"mean =\",mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time = 15.995240999999993\n",
      "k = 1 euclidean mean = 0.157061986984 weights on\n",
      "k = 2 euclidean mean = 0.156797367756 weights on\n",
      "k = 3 euclidean mean = 0.151847661813 weights on\n",
      "k = 4 euclidean mean = 0.14566079302 weights on\n",
      "k = 5 euclidean mean = 0.141506444551 weights on\n",
      "k = 6 euclidean mean = 0.134347243044 weights on\n",
      "k = 7 euclidean mean = 0.126215708821 weights on\n",
      "k = 8 euclidean mean = 0.117023377698 weights on\n",
      "k = 9 euclidean mean = 0.113222628197 weights on\n",
      "k = 10 euclidean mean = 0.110128959458 weights on\n",
      "time = 14.093612000000007\n",
      "k = 1 cosine mean = 0.589358271657 weights on\n",
      "k = 2 cosine mean = 0.589269901208 weights on\n",
      "k = 3 cosine mean = 0.589976630457 weights on\n",
      "k = 4 cosine mean = 0.588032011896 weights on\n",
      "k = 5 cosine mean = 0.583877804033 weights on\n",
      "k = 6 cosine mean = 0.581403361161 weights on\n",
      "k = 7 cosine mean = 0.575923338788 weights on\n",
      "k = 8 cosine mean = 0.573006457815 weights on\n",
      "k = 9 cosine mean = 0.570708591801 weights on\n",
      "k = 10 cosine mean = 0.568587560422 weights on\n"
     ]
    }
   ],
   "source": [
    "#Task14\n",
    "for k in [\"euclidean\",\"cosine\"]:\n",
    "    start=time.clock()\n",
    "    a=cross_validation.knn_cross_val_score(tfidf,ans,[1,2,3,4,5,6,7,8,9,10],score=\"accuracy\",cv=cross_validation.kfold(tfidf.shape[0],3),weights=True,metric=k,strategy=\"brute\",test_block_size=20)\n",
    "    print(\"time =\",time.clock()-start)\n",
    "    for i in a:\n",
    "        mean=np.sum(a[i])/len(a[i])\n",
    "        print(\"k =\",i,k,\"mean =\",mean,\"weights on\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Требовалось загрузить 20newsgroups, в которой документы, содержащие слова, преобразовать ее в разреженную матрицу и сравнить по кросс-валидации точность и скорость метода k ближайщих соседей при разных параметрах. Использовался метод \"brute\", нахваленный своей скоростью. Данные в таблице показывают точность. **Weights** означает взвешенный ли методы был, **Time** - время, за которое выполнил алгоритм, **Metric** - использовавшася метрика."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Time| Weights | Metric | k=1 |k=2|k=3|k=4|k=5|k=6|k=7|k=8|k=9|k=10|\n",
    "|:-----------: |:-----------:|:-----------:|:-----------:|:-----------:|:-----------:|:-----------:|:-----------:|:-----------:|:-----------:|:-----------:|:-----------:|:-----------:|\n",
    "|14.00s| False       | Euclidean       | 0.1533       |0.1146|0.1073|0.1032|0.0987|0.0956|0.0937|0.0920|0.0890|0.0856|\n",
    "|11.75s| False       | Cosine       | 0.5824       |0.5492|0.5525|0.5568|0.5593|0.5546|0.5513|0.5499|0.5476|0.5447|\n",
    "|15.99s|   True     | Euclidean       | 0.1570       |0.1567|0.1518|0.1456|0.1415|0.1343|0.1262|0.1170|0.1132|0.1101|\n",
    "|14.09s| True       | Cosine       | 0.5893     |0.5892|0.5899|0.5880|0.5838|0.5814|0.5759|0.5730|0.5707|0.5668|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Косинусная метрика показала контрастный результат в сравнении с евклидовой: выполнялась быстрее, точность заметно лучше. Поэтому на тестовой выборке 20newsgroups я использовал классификатор с параметрами: k=3, metric=\"cosine\", weights=True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Task15\n",
    "control2=fetch_20newsgroups(subset='test',remove=('headers', 'footers', 'quotes'))\n",
    "control=control2['data']\n",
    "ans2=control2['target']\n",
    "control=[''.join((c if c.isalnum() else ' ') for c in s.lower()) for s in control]\n",
    "test=[c.split() for c in control]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Task15\n",
    "indptr2 = [0]\n",
    "indices2 = []\n",
    "data2 = []\n",
    "for d in test:\n",
    "    for term in d:\n",
    "        index2 = vocabulary.setdefault(term)\n",
    "        if(index2!=None):\n",
    "            indices2.append(index2)\n",
    "            data2.append(1)\n",
    "    indptr2.append(len(indices2))\n",
    "shape2=len(test)\n",
    "y_csr=csr_matrix((data2, indices2, indptr2), shape=(shape2,shape1),dtype=float).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Task15\n",
    "transformer2=TfidfTransformer()\n",
    "test=transformer2.fit_transform(y_csr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Task15\n",
    "classifier=nearest_neighbors.KNN_classifier(k=3,strategy='brute',metric='cosine',test_block_size=20,weights=True)\n",
    "classifier.fit(tfidf,ans)\n",
    "y_pred=classifier.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.51035581518852891"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Task15\n",
    "np.sum(y_pred==ans2)/len(ans2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Точность оказалась равной 0.5122, не очень близкой к кросс-валидационной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[156,   1,   5,   1,   1,   3,   3,   7,   7,   5,   3,   7,   9,\n",
       "         23,  18,  63,  13,  39,  25,  43],\n",
       "       [  0, 187,  17,  13,   8,  30,   3,   9,   3,   1,   0,   5,  12,\n",
       "          8,   9,   0,   2,   1,   1,   0],\n",
       "       [  3,  30, 190,  37,  16,  25,   9,   0,   7,   2,   3,   3,   9,\n",
       "          1,   5,   0,   3,   0,   0,   1],\n",
       "       [  2,  14,  32, 213,  45,   6,  42,   4,   6,   2,   0,   5,  18,\n",
       "          4,   1,   1,   2,   3,   3,   2],\n",
       "       [ 10,  15,  27,  38, 209,   8,  39,  26,  20,  16,  12,  20,  41,\n",
       "         16,  25,  14,  11,   6,   9,   8],\n",
       "       [  0,  36,  22,   7,   7, 263,   7,   1,   5,   2,   1,   2,  11,\n",
       "          1,   3,   0,   2,   1,   1,   2],\n",
       "       [  0,   6,  12,  14,   9,   5, 194,  12,   1,   4,   2,   4,   6,\n",
       "          2,   1,   1,   3,   1,   3,   2],\n",
       "       [  4,   5,   4,   7,   5,   1,  16, 206,  25,   5,   4,   2,  10,\n",
       "          5,   8,   1,   6,   4,   4,   6],\n",
       "       [  2,   7,   4,   1,   1,   2,   9,  19, 196,   5,   3,   4,  11,\n",
       "          8,   6,   2,   2,   5,   1,   3],\n",
       "       [  2,   6,   5,   3,   0,  12,   9,   8,   4, 223,  17,   4,   7,\n",
       "          3,   8,   3,   6,   4,   1,   3],\n",
       "       [  4,   4,   2,   2,   2,   3,   6,   2,   2,  26, 276,   9,   7,\n",
       "          3,   4,   0,   3,   1,   6,   1],\n",
       "       [  8,  18,   4,  13,   7,   7,   2,   4,   7,   1,   3, 235,  27,\n",
       "          9,  12,   2,  19,   7,   6,  10],\n",
       "       [  3,   6,   3,  13,   8,   4,  11,  18,   5,   2,   3,   3, 134,\n",
       "          5,  12,   0,   1,   1,   2,   0],\n",
       "       [  5,   7,   6,   4,   4,   1,   5,   4,   6,   5,   4,   5,  12,\n",
       "        198,   6,   6,   5,   3,   2,   6],\n",
       "       [  5,   7,  10,   2,   4,   3,   6,   7,   5,   5,   2,   1,   6,\n",
       "          4, 187,   2,   3,   2,   4,   2],\n",
       "       [ 35,   8,  11,   3,  17,   3,   4,  11,  20,  15,  10,  14,  19,\n",
       "         31,   7, 230,  16,  16,   8,  52],\n",
       "       [  7,   1,   1,   2,   8,   2,   2,   3,   7,   4,   2,   9,   4,\n",
       "          5,   7,   3, 157,  17,  66,  16],\n",
       "       [ 29,  10,  16,  10,  14,   6,   9,  29,  44,  55,  48,  32,  30,\n",
       "         33,  32,  26,  68, 235,  46,  14],\n",
       "       [ 10,  16,  11,   6,  17,   8,   5,  17,  16,  11,   2,  21,  12,\n",
       "         21,  33,   9,  24,  17,  99,  10],\n",
       "       [ 34,   5,  12,   3,   3,   3,   9,   9,  12,   8,   4,  11,   8,\n",
       "         16,  10,  35,  18,  13,  23,  70]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Task16\n",
    "confusion_matrix(y_pred, ans2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значения на диагональных элемнтах довольно-таки невысокие, что говорит о не очень хорошем классификаторе. Много слов не было распознано, что показывают величины на внедиагональных элементах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывел документы, на которых были допущены ошибки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1:\n",
      "Hello all,\n",
      "   I need to make  some torso 3D scans and would like the phone numbers of\n",
      "companies in the midwest that make scans, and the numbers of companies that\n",
      "make the sanners (ie Cyberware). Does anyone have an idea of how much a\n",
      "single scan costs and the best format to save it in? I am not sure on what\n",
      "software platform I will be using it in, probably either Softimage or\n",
      "Wavefront. So I think a spline based format would be best. Please forward the\n",
      "numbers to me personally as I am having problems accessing USENET lately.\n",
      "Thanks in advance!\n",
      "\n",
      "Text 2:\n",
      "I have a lots of .cgm files produced by NCAR Graph Utility V3.00.\n",
      "\n",
      "They are all color graphs, and I want to print them out. \n",
      "\n",
      "The printers I own are Postscript, and HP 7475a. Anyone who have \n",
      "\n",
      "experiences in this please tell me, e-mail me will be very nice.\n",
      "\n",
      "Or if someone knows how to convert those .cgm  files into .gif\n",
      "\n",
      "pcx, .bmp .... , it will helps a lot. \n",
      "\n",
      "\n",
      "Text 3:\n",
      "I'm told that VRrend386 is available on the internet. I wanted to know where it is.\n",
      "\n",
      "Thanks in advance.\n",
      "\n",
      "Raoul\n"
     ]
    }
   ],
   "source": [
    "#Task16\n",
    "print(\"Text 1:\")\n",
    "cur=np.where((ans2==1)&(ans2!=y_pred))[0]\n",
    "np.random.shuffle(cur)\n",
    "print(control2['data'][cur[1]])\n",
    "\n",
    "print(\"\\nText 2:\")\n",
    "cur=np.where((ans2==1)&(ans2!=y_pred))[0]\n",
    "np.random.shuffle(cur)\n",
    "print(control2['data'][cur[1]])\n",
    "\n",
    "print(\"\\nText 3:\")\n",
    "cur=np.where((ans2==1)&(ans2!=y_pred))[0]\n",
    "np.random.shuffle(cur)\n",
    "print(control2['data'][cur[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В обоих выборках косинусная метрика с взешенными весами показала лучший результат, нежели евклидовая. Это связно с тем, что она лучше работает в задачах распознавания рукописных цифр и схожести между текстами. К тому же в ней производится нормировка на длины векторов, благодаря чему она не зависит от размеров сравниваемых текстов. Поэтому при подобных задачах нужно пользоваться ей, а параметр k выбирать с помощью кросс-валидации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Список литературы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Markdown Tutorial](http://www.markdowntutorial.com/)\n",
    "\n",
    "[Найдется всё!](http://google.ru)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
